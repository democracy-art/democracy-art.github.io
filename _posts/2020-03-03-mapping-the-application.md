---
layout:     post
title:      Web应用程序技术 - Chapter 4 - Mapping the Application
subtitle:   
date:       2020-03-03
author:     D
header-img: 
catalog: true
mermaid: true
tags:
    - [web hacking]
---

参考:*The Web Application Hacker's Handbook* 
Chapter 4 Mapping the Application


攻击应用程序的第一步是收集和检查有关该应用程序的一些关键信息，以更好地了解您所面临的挑战。

映射练习首先枚举应用程序的`内容`和`功能`，以了解应用程序的功能以及行为方式。 此功能的大部分易于识别，但其中某些功能可能是`隐藏`的，需要一定程度的猜测和运气才能发现。

主要任务是仔细检查其行为的各个方面，其核心`安全机制`以及所采`用的技术`（在`客户端`和`服务器`上）。 这将使您能够识别应用程序暴露的主要`攻击面`，从而可以确定最有趣的`区域`，应在这些区域中进行后续探测以发现可利用的漏洞。

随着应用程序变得越来越大，功能越来越多，`有效的映射`是一项宝贵的技能。 经验丰富的专家可以`快速`对功能的所有区域进行分类，查找与实例相对应的漏洞类别，同时将大量时间投入到测试其他特定领域，以发现`高风险`问题。

本章描述了在应用`程序映射`过程中需要遵循的实际`步骤`，可以用来`最大化`其`有效性`的各种技术和技巧，以及一些可以在此过程中帮助您的工具。

# 1. Enumerating Content and Functionality(枚举内容和功能)

在典型的应用程序中，大多数内容和功能都可以通过`手动浏览`来识别。基本的方法是`遍历`应用程序，从主初始页面开始，跟踪每个`链接`，并通过导航控制所有多级功能(如`用户注册`或`密码重置`)。如果应用程序包含`site map`，这可以为枚举内容提供一个有用的起点。

然而，要对列举的内容进行严格的检查，并获得所标识的所有内容的完整记录，您必须使用比简单浏览更高级的技术。

## 1.1 Web Spidering(网络爬虫)
各种工具可以执行自动的网站搜索,这些工具的工作方式是:请求一个web页面,解析它以获得到其他内容的链接,请求这些链接,然后递归地继续操作,直到没有发现新的内容为止.

工具:Burp Suite, WebScarab, Zed Attack, CAT.

许多Web服务器在Web根目录中包含一个名为`robots.txt`的文件，该文件包含该站点**不**希望Web蜘蛛访问或搜索引擎建立索引的URL列表。 有时，robots.txt文件可能会对Web应用程序的安全起反作用。

1.1.1.1 自动化网络爬虫限制
- 不寻常的导航机制(比如:使用复杂的JavaScript代码动态创建和处理菜单)通常不会被自动化工具正确地处理,因此它们可能错过应用程序的整个区域.
- 隐藏在已编译的客户端对象(如:Flash或Java applet)中的链接可能不会被爬行器捕获.
- 多阶段功能通常实现细粒度的输入验证检查,这些检查不接受自动化工具可能提交的值。例如，用户注册表单可能包含的名称，电子邮件地址，电话号码和邮政编码的字段。因此它不会越过注册表单，因此不会发现除了注册表单之外的其他任何内容或功能.
- 自动化的爬虫通常使用URL作为唯一内容的标识符.为了避免持续的爬取,它们识别已经被请求的链接内容,且不再请求它.然而,许多应用程序使用基于表单的导航,其中相同的URL可能返回不同的内容和功能.
- 与前一点相反,一些应用程序将易变数据放在URL中,这些URL实际上并不用于识别资源或函数(如:包含计时器或随机数种子的参数).应用程序的每个页面可能包含一组新的URL,爬虫必须请求这些URL,将导致它无限的去爬取.
- 当应用程序使用身份验证时，有效的应用程序爬行器必须能够处理这个问题，以访问身份验证保护的功能。前面提到的爬行器可以通过手动配置爬行器来实现这一点，可以使用经过身份验证的会话的令牌，也可以使用提交到登录函数的凭据来配置爬行器。但是，即使这样做了，通常也会发现spider的操作会由于各种原因中断经过身份验证的会话:
	- 通过跟踪所有URL，爬行器将在某个时候请求注销功能，导致其会话中断。
	- 如果爬行器将无效的输入提交给敏感函数，则应用程序可以防御性地终止会话。
	- 如果应用程序使用每页令牌，则爬虫几乎肯定会通过请求超出其预期顺序的页面而无法正确处理这些令牌，这可能导致整个会话终止。

## 1.2 User-Directed Spidering(用户控制的爬虫)

这是一种更复杂、更可控的技术，通常比自动蜘蛛更受欢迎。在这里，用户使用标准的浏览器以正常的方式浏览应用程序，试图浏览所有的应用程序功能。当他这样做时，结果的流量通过一个结合了拦截代理和爬行器的工具传递，爬行器监视所有请求和响应。该工具构建应用程序的地图，对浏览器访问的所有url进行分级。它还以与普通应用程序感知爬行器相同的方式解析所有应用程序响应，并使用它发现的内容和功能更新站点地图。Burp套件和WebScarab中的spider可以以这种方式使用(有关更多信息，请参见第20章)。

与自动爬虫相比,用户控制爬虫的好处:
- 当应用程序使用不同寻常或复杂的导航机制时，用户可以使用浏览器以正常的方式跟踪这些机制。用户访问的任何函数和内容都由proxy/spider工具处理。
- 用户控制提交给应用程序的所有数据，并确保满足数据验证需求。
- 用户可以以通常的方式登录到应用程序，并确保经过身份验证的会话在整个映射过程中保持活动。如果执行的任何操作导致会话终止，用户可以再次登录并继续浏览。
- 任何危险的功能，如`deleteUser.jsp`，都是完全枚举的，并合并到代理的站点地图中，因为到它的链接将从应用程序的响应中解析出来。但是用户可以自行决定实际请求或执行哪些功能。

**HACK STEPS**
- 将您的浏览器配置为使用Burp作为本地代理
- 正常浏览整个应用程序，尝试访问您发现的每个`link/URL`，提交每个`表单`，并通过所有多步骤功能完成。尝试在启用和禁用`JavaScript`以及启用和禁用`cookie`的情况下进行浏览。许多应用程序可以处理不同的浏览器配置，您可以在应用程序中访问不同的内容和代码路径。
- 检查由proxy/spider工具生成的站点地图，并确定没有手动浏览的任何应用程序内容或功能。建立爬行器如何枚举每个项。例如，在Burp Spider中，检查来自details的链接。使用您的浏览器，手动访问项目，以便proxy/spider工具解析来自服务器的响应，以识别任何进一步的内容。递归地继续这一步，直到没有进一步的内容或功能被识别。
- 可选地，告诉工具使用所有已枚举的内容作为起点来主动地爬行站点。要做到这一点，首先要识别出任何危险的或可能破坏应用程序会话的url，并配置确保爬行器将这些url从其范围中排除。运行爬行器并查看其发现的任何附加内容的结果。

由proxy/spider工具生成的站点地图包含大量关于目标应用程序的信息，这些信息在以后识别应用程序公开的各种攻击面时会很有用。

## 1.3 Discovering Hidden Content(挖掘隐藏的内容)

应用程序通常包含不直接链接到主可视内容或不能从主可视内容访问的内容和功能。一个常见的例子是为`测试`或`调试`目的而实现的功能，并且从未被删除。
发现该功能的攻击者可能会利用它来`提高`她在应用程序中的`特权`。

还有无数其他情况，其中可能存在前面描述的映射技术无法识别的有趣**内容和功能**:
- 实时文件的备份副本。 对于动态页面，其文件扩展名可能已更改为未映射为可执行文件的文件扩展名，使您可以查看页面源中的漏洞，然后可以在实时页面上利用这些漏洞。
- 备份存档包含Web根内部（或实际上位于外部）的文件的完整快照，可能使您能够轻松识别应用程序内的所有内容和功能。
- 已部署到服务器进行测试但尚未与主应用程序链接的新功能。
- 现成的应用程序中的默认应用程序功能已向用户表面隐藏，但仍在服务器上。
- 尚未从服务器中删除的文件的旧版本。 对于动态页面，这些页面可能包含在当前版本中已修复但在旧版本中仍可利用的漏洞。
- 配置并包括包含敏感数据（例如数据库凭据）的文件。
- 配置并包括包含敏感数据（例如数据库凭据）的文件。
- 源代码中的注释在极端情况下可能包含用户名和密码等信息，但更有可能提供有关应用程序状态的信息。 测试此功能或类似内容之类的关键短语是从哪里开始寻找漏洞的有力指标。
- 日志文件可能包含敏感信息，例如有效的用户名，会话令牌，访问的URL和执行的操作。

有效发现隐藏内容需要自动和手动技术的结合，并且通常取决于运气。

### 1.3.1 暴力破解技术(Brute-Force Techniques)

第14章介绍了如何利用自动化技术来加快对应用程序的任何攻击。 在当前的信息收集环境中，可以使用自动化向Web服务器发出大量请求，以尝试猜测隐藏功能的名称或标识符。

自动识别隐藏内容的第一步可能包括以下请求，以定位其他目录:
```
http://eis/About/
http://eis/abstract/
http://eis/academics/
http://eis/accessibility/
http://eis/accounts/
http://eis/action/
...
```
Burp Intruder可用于遍历常见目录名称列表并捕获服务器响应的详细信息，可对其进行查看以识别有效目录。 图4-4显示了Burp Intruder被配置为探测位于Web根目录的公用目录。

![figure4-4](/img/web_hacking/twahh/figure4-4.jpg)
图4-4

执行攻击后，单击`status`和`length`之类的列标题会相应地对结果进行排序，使您能够`快速识别`潜在的其他资源列表，如图4-5所示。 对目录和子目录进行暴力破解后，您可能希望在应用程序中查找其他页面。 特别令人感兴趣的是`/auth`目录，其中包含在爬网过程中标识的登录资源，对于未经身份验证的攻击者来说，这很可能是一个很好的起点。 同样，您可以在此目录中请求一系列文件:

```
http://eis/auth/About/
http://eis/auth/Aboutus/
http://eis/auth/AddUser/
http://eis/auth/Admin/
http://eis/auth/Administration/
http://eis/auth/Admins/
...
```
![figure4-5](/img/web_hacking/twahh/figure4-5.jpg)
图4-5

图4-6显示了这次攻击的结果，它在/auth目录中标识了几个资源:
```
Login
Logout
Register
Profile
```
请注意，对`Profile`的请求返回HTTP状态代码`302`。这表示在未经身份验证的情况下访问此链接会将用户重定向到登录页面。 更令人感兴趣的是，尽管在抓取过程中发现了“登录”页面，但**没**有发现“注册”页面。 此额外功能可能是**可操作**的，并且攻击者可能在站点上注册了用户帐户。

![figure4-6](/img/web_hacking/twahh/figure4-6.jpg)
图4-6

**注意:**
**不**要假设如果请求的资源存在，应用程序将以200 OK响应;如果不存在，则以404 not Found响应。许多应用程序以定制的方式处理对不存在资源的请求，通常返回定制的错误消息和200个响应代码。此外，对现有资源的一些请求可能会收到一个非200的响应。这是一个粗略的指南，告诉你在寻找隐藏内容的蛮力练习中可能遇到的响应代码的可能含义:
- `302 Found` - 如果重定向到一个登录页面，资源可能只有通过身份验证的用户才能访问。如果重定向到错误消息，则可能指示不同的原因。如果是到另一个位置，则重定向可能是应用程序预期逻辑的一部分，应该进一步研究这一点。
- `400 Bad Request` - 应用程序可能会为URL中的`目录`和`文件`使用自定义`命名方案`，而特定请求未遵循该方案。但是，更可能的是您使用的单词列表包含一些`空格字符`或其他`无效的语法`。 
- `401 Unauthorized or 403 Forbidden` - 这通常表示请求的资源`存在`，但是任何用户都不能访问它，无论身份验证状态或特权级别如何。它通常在请求目录时发生，您可以推断该目录存在。
- `501 Internal Server Error` - 在内容发现期间，这通常表示应用程序期望在请求资源时提交某些参数。

可能指示有趣内容存在的各种可能的响应意味着很难编写全自动脚本来输出有效资源列表。 最好的方法是在蛮力练习中捕获尽可能多的有关应用程序响应的信息，然后手动进行检查。

**HACK STEPS**
- 1.手动请求已知的有效和无效资源，并确定服务器如何处理后者。
- 2.使用通过用户控制的爬虫生成的site-map作为自动发现隐藏内容的基础。
- 3.对应用程序中已知存在的每个目录或路径中的通用文件名和目录发出自动请求。 使用Burp Intruder或自定义脚本，以及常见文件和目录的单词列表，可以快速生成大量请求。 如果您确定了应用程序处理无效资源请求的特定方式（例如，未找到自定义文件的页面），请配置Intruder或脚本以突出显示这些结果，以便将其忽略。
- 4.捕获从服务器收到的响应，然后手动检查它们以识别有效资源。
- 5.发现新内容后，递归执行上面步骤。

### 1.3.2 从发布的内容推断(Inference from Published Content)
大多数应用程序为其内容和功能采用某种命名方案。 通过从应用程序中已经确定的资源推断出，可以对自动枚举进行微调，以增加发现更多隐藏内容的可能性。

在EIS应用程序中，请注意/auth中的所有资源均以大写字母开头。 这就是为什么在上一节的暴力破解中使用的单词表是**故意**大写的原因。 此外，由于我们已经在/auth目录中标识了一个名为`ForgotPassword`的页面，因此我们可以搜索名称相似的项，例如以下内容:
```
http://eis/auth/ResetPassword
```
此外，在用户控制抓取过程中创建的站点地图识别了这些资源:
```
http://eis/pub/media/100
http://eis/pub/media/117
http://eis/pub/user/11
```
相似范围内的**其他数值**可能会标识其他资源和信息。

**Burp Intruder**具有高度可定制性，可用于定位HTTP请求的任何部分。 图4-7显示了Burp Intruder用于对文件名的前半部分执行暴力攻击以发出请求：
```
http://eis/auth/AddPassword
http://eis/auth/ForgotPassword
http://eis/auth/GetPassword
http://eis/auth/ResetPassword
http://eis/auth/RetrievePassword
http://eis/auth/UpdatePassword
...
```
![figure4-7](/img/web_hacking/twahh/figure4-7.jpg)

**HACK STEPS**
- 1.查看用户控制的浏览和基本的暴力练习的结果。 编译所有枚举子目录的名称，文件干和文件扩展名的列表。
- 2.查看这些列表以识别正在使用的任何命名方案。 例如，如果有称为`AddDocument.jsp`和`ViewDocument.jsp`的页面，则也可能有称为`EditDocument.jsp`和`RemoveDocument.jsp`的页面。 通过阅读一些示例，您通常可以感觉到开发人员的**命名习惯**。 例如，根据开发人员的个人风格，开发人员可能比较冗长（`AddANewUser.asp`），简洁（`AddUser.asp`），使用缩写（`AddUsr.asp`）甚至是比较晦涩的（`AddU.asp`）。 了解使用的命名方式可能有助于您猜测尚未标识的内容的准确名称。
- 3.有时，用于不同内容的命名方案使用诸如**数字和日期**之类的标识符，这可以使推断隐藏内容变得容易。 最常见的是静态资源而不是动态脚本的名称。 例如，如果公司的网站链接到`AnnualReport2009.pdf`和`AnnualReport2010.pdf`，则应该很短的步骤来确定将调用下一个报告。 令人难以置信的是，有一些臭名昭著的案例，即公司在公开发布之前将包含财务报告的文件放置在其Web服务器上，而只是让记者根据以前使用的命名方案巧妙地发现它们。
- 4.查看**所有**客户端代码（例如`HTML`和`JavaScript`），以确定有关隐藏的服务器端内容的任何线索。这些可能包括与受保护或未链接的函数有关的**HTML注释**，带有**禁用**的SUBMIT元素的**HTML表单**等。通常，**注释**是由用来生成Web内容的软件或运行应用程序的平台自动生成的。对诸如服务器端**包含文件**之类的项目的引用特别受关注。这些文件实际上**可以公开下载**，并且可能包含高度敏感的信息，例如数据库连接字符串和密码。在其他情况下，开发人员**注释**可能包含各种有用的花絮，例如数据库名称，对后端组件的引用，SQL查询字符串等。诸如`Java applet`和`ActiveX`控件之类的胖客户端组件也可能包含您可以提取的敏感数据。有关应用程序可以公开其自身信息的更多方式，请参见第15章。
- 5.


## 1.4 Application Pages Versus Functional Paths(应用程序页面与功能路径)
## 1.5 Discovering Hidden Parameters(挖掘隐藏的参数)

# 2. Analyzing the Application(分析程序)
## 2.1 Identifying Entry Points for User Input(识别用户输入的入口点)
## 2.2 Identifying Server-Side Technologies(识别服务器端技术)
## 2.3 Identifying Server-Side Functionality(识别服务器端功能)
## 2.4 Mapping the Attack Surface(绘制攻击面)

[Web应用程序技术 - Chapter 3(2) - Web Functionality and Encoding Schemes](https://dm116.github.io/2020/03/03/web-application-technologies_2)
