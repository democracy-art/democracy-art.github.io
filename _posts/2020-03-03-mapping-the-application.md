---
layout:     post
title:      Web应用程序技术 - Chapter 4 - Mapping the Application
subtitle:   
date:       2020-03-03
author:     D
header-img: 
catalog: true
mermaid: true
tags:
    - [web hacking]
---

参考:*The Web Application Hacker's Handbook* 
Chapter 4 Mapping the Application


攻击应用程序的第一步是收集和检查有关该应用程序的一些关键信息，以更好地了解您所面临的挑战。

映射练习首先枚举应用程序的`内容`和`功能`，以了解应用程序的功能以及行为方式。 此功能的大部分易于识别，但其中某些功能可能是`隐藏`的，需要一定程度的猜测和运气才能发现。

主要任务是仔细检查其行为的各个方面，其核心`安全机制`以及所采`用的技术`（在`客户端`和`服务器`上）。 这将使您能够识别应用程序暴露的主要`攻击面`，从而可以确定最有趣的`区域`，应在这些区域中进行后续探测以发现可利用的漏洞。

随着应用程序变得越来越大，功能越来越多，`有效的映射`是一项宝贵的技能。 经验丰富的专家可以`快速`对功能的所有区域进行分类，查找与实例相对应的漏洞类别，同时将大量时间投入到测试其他特定领域，以发现`高风险`问题。

本章描述了在应用`程序映射`过程中需要遵循的实际`步骤`，可以用来`最大化`其`有效性`的各种技术和技巧，以及一些可以在此过程中帮助您的工具。

# 1. Enumerating Content and Functionality(枚举内容和功能)

在典型的应用程序中，大多数内容和功能都可以通过`手动浏览`来识别。基本的方法是`遍历`应用程序，从主初始页面开始，跟踪每个`链接`，并通过导航控制所有多级功能(如`用户注册`或`密码重置`)。如果应用程序包含`site map`，这可以为枚举内容提供一个有用的起点。

然而，要对列举的内容进行严格的检查，并获得所标识的所有内容的完整记录，您必须使用比简单浏览更高级的技术。

### 1.1 Web Spidering(网络爬虫)
各种工具可以执行自动的网站搜索,这些工具的工作方式是:请求一个web页面,解析它以获得到其他内容的链接,请求这些链接,然后递归地继续操作,直到没有发现新的内容为止.

工具:Burp Suite, WebScarab, Zed Attack, CAT.

许多Web服务器在Web根目录中包含一个名为`robots.txt`的文件，该文件包含该站点**不**希望Web蜘蛛访问或搜索引擎建立索引的URL列表。 有时，robots.txt文件可能会对Web应用程序的安全起反作用。

1.1.1.1 自动化网络爬虫限制
- 不寻常的导航机制(比如:使用复杂的JavaScript代码动态创建和处理菜单)通常不会被自动化工具正确地处理,因此它们可能错过应用程序的整个区域.
- 隐藏在已编译的客户端对象(如:Flash或Java applet)中的链接可能不会被爬行器捕获.
- 多阶段功能通常实现细粒度的输入验证检查,这些检查不接受自动化工具可能提交的值。例如，用户注册表单可能包含的名称，电子邮件地址，电话号码和邮政编码的字段。因此它不会越过注册表单，因此不会发现除了注册表单之外的其他任何内容或功能.
- 自动化的爬虫通常使用URL作为唯一内容的标识符.为了避免持续的爬取,它们识别已经被请求的链接内容,且不再请求它.然而,许多应用程序使用基于表单的导航,其中相同的URL可能返回不同的内容和功能.
- 与前一点相反,一些应用程序将易变数据放在URL中,这些URL实际上并不用于识别资源或函数(如:包含计时器或随机数种子的参数).应用程序的每个页面可能包含一组新的URL,爬虫必须请求这些URL,将导致它无限的去爬取.
- 当应用程序使用身份验证时，有效的应用程序爬行器必须能够处理这个问题，以访问身份验证保护的功能。前面提到的爬行器可以通过手动配置爬行器来实现这一点，可以使用经过身份验证的会话的令牌，也可以使用提交到登录函数的凭据来配置爬行器。但是，即使这样做了，通常也会发现spider的操作会由于各种原因中断经过身份验证的会话:
	- 通过跟踪所有URL，爬行器将在某个时候请求注销功能，导致其会话中断。
	- 如果爬行器将无效的输入提交给敏感函数，则应用程序可以防御性地终止会话。
	- 如果应用程序使用每页令牌，则爬虫几乎肯定会通过请求超出其预期顺序的页面而无法正确处理这些令牌，这可能导致整个会话终止。

### 1.2 User-Directed Spidering(用户控制的爬虫)

这是一种更复杂、更可控的技术，通常比自动蜘蛛更受欢迎。在这里，用户使用标准的浏览器以正常的方式浏览应用程序，试图浏览所有的应用程序功能。当他这样做时，结果的流量通过一个结合了拦截代理和爬行器的工具传递，爬行器监视所有请求和响应。该工具构建应用程序的地图，对浏览器访问的所有url进行分级。它还以与普通应用程序感知爬行器相同的方式解析所有应用程序响应，并使用它发现的内容和功能更新站点地图。Burp套件和WebScarab中的spider可以以这种方式使用(有关更多信息，请参见第20章)。

与自动爬虫相比,用户控制爬虫的好处:
- 当应用程序使用不同寻常或复杂的导航机制时，用户可以使用浏览器以正常的方式跟踪这些机制。用户访问的任何函数和内容都由proxy/spider工具处理。
- 用户控制提交给应用程序的所有数据，并确保满足数据验证需求。
- 用户可以以通常的方式登录到应用程序，并确保经过身份验证的会话在整个映射过程中保持活动。如果执行的任何操作导致会话终止，用户可以再次登录并继续浏览。
- 任何危险的功能，如`deleteUser.jsp`，都是完全枚举的，并合并到代理的站点地图中，因为到它的链接将从应用程序的响应中解析出来。但是用户可以自行决定实际请求或执行哪些功能。

**HACK STEPS**<br>
- 将您的浏览器配置为使用Burp作为本地代理
- 正常浏览整个应用程序，尝试访问您发现的每个`link/URL`，提交每个`表单`，并通过所有多步骤功能完成。尝试在启用和禁用`JavaScript`以及启用和禁用`cookie`的情况下进行浏览。许多应用程序可以处理不同的浏览器配置，您可以在应用程序中访问不同的内容和代码路径。
- 检查由proxy/spider工具生成的站点地图，并确定没有手动浏览的任何应用程序内容或功能。建立爬行器如何枚举每个项。例如，在Burp Spider中，检查来自details的链接。使用您的浏览器，手动访问项目，以便proxy/spider工具解析来自服务器的响应，以识别任何进一步的内容。递归地继续这一步，直到没有进一步的内容或功能被识别。
- 可选地，告诉工具使用所有已枚举的内容作为起点来主动地爬行站点。要做到这一点，首先要识别出任何危险的或可能破坏应用程序会话的url，并配置确保爬行器将这些url从其范围中排除。运行爬行器并查看其发现的任何附加内容的结果。

由proxy/spider工具生成的站点地图包含大量关于目标应用程序的信息，这些信息在以后识别应用程序公开的各种攻击面时会很有用。

### 1.3 Discovering Hidden Content(挖掘隐藏的内容)
应用程序通常包含不直接链接到主可视内容或不能从主可视内容访问的内容和功能。一个常见的例子是为`测试`或`调试`目的而实现的功能，并且从未被删除。
发现该功能的攻击者可能会利用它来`提高`她在应用程序中的`特权`。

还有无数其他情况，其中可能存在前面描述的映射技术无法识别的有趣**内容和功能**:
- 实时文件的备份副本。 对于动态页面，其文件扩展名可能已更改为未映射为可执行文件的文件扩展名，使您可以查看页面源中的漏洞，然后可以在实时页面上利用这些漏洞。
- 备份存档包含Web根内部（或实际上位于外部）的文件的完整快照，可能使您能够轻松识别应用程序内的所有内容和功能。
- 已部署到服务器进行测试但尚未与主应用程序链接的新功能。
- 现成的应用程序中的默认应用程序功能已向用户表面隐藏，但仍在服务器上。
- 尚未从服务器中删除的文件的旧版本。 对于动态页面，这些页面可能包含在当前版本中已修复但在旧版本中仍可利用的漏洞。
- 配置并包括包含敏感数据（例如数据库凭据）的文件。
- 配置并包括包含敏感数据（例如数据库凭据）的文件。
- 源代码中的注释在极端情况下可能包含用户名和密码等信息，但更有可能提供有关应用程序状态的信息。 测试此功能或类似内容之类的关键短语是从哪里开始寻找漏洞的有力指标。
- 日志文件可能包含敏感信息，例如有效的用户名，会话令牌，访问的URL和执行的操作。

有效发现隐藏内容需要自动和手动技术的结合，并且通常取决于运气。

第14章介绍了如何利用自动化技术来加快对应用程序的任何攻击。 在当前的信息收集环境中，可以使用自动化向Web服务器发出大量请求，以尝试猜测隐藏功能的名称或标识符。

自动识别隐藏内容的第一步可能包括以下请求，以定位其他目录:
```
http://eis/About/
http://eis/abstract/
http://eis/academics/
http://eis/accessibility/
http://eis/accounts/
http://eis/action/
...
```
Burp Intruder可用于遍历常见目录名称列表并捕获服务器响应的详细信息，可对其进行查看以识别有效目录。 图4-4显示了Burp Intruder被配置为探测位于Web根目录的公用目录。

![figure4-4](/img/web_hacking/twahh/figure4-4.jpg)
图4-4

执行攻击后，单击`status`和`length`之类的列标题会相应地对结果进行排序，使您能够`快速识别`潜在的其他资源列表，如图4-5所示。 对目录和子目录进行暴力破解后，您可能希望在应用程序中查找其他页面。 特别令人感兴趣的是`/auth`目录，其中包含在爬网过程中标识的登录资源，对于未经身份验证的攻击者来说，这很可能是一个很好的起点。 同样，您可以在此目录中请求一系列文件:

```
http://eis/auth/About/
http://eis/auth/Aboutus/
http://eis/auth/AddUser/
http://eis/auth/Admin/
http://eis/auth/Administration/
http://eis/auth/Admins/
...
```
![figure4-5](/img/web_hacking/twahh/figure4-5.jpg)
图4-5

图4-6显示了这次攻击的结果，它在/auth目录中标识了几个资源:
```
Login
Logout
Register
Profile
```
请注意，对`Profile`的请求返回HTTP状态代码`302`。这表示在未经身份验证的情况下访问此链接会将用户重定向到登录页面。 更令人感兴趣的是，尽管在抓取过程中发现了“登录”页面，但**没**有发现“注册”页面。 此额外功能可能是**可操作**的，并且攻击者可能在站点上注册了用户帐户。

![figure4-6](/img/web_hacking/twahh/figure4-6.jpg)
图4-6

**注意:**
**不**要假设如果请求的资源存在，应用程序将以200 OK响应;如果不存在，则以404 not Found响应。许多应用程序以定制的方式处理对不存在资源的请求，通常返回定制的错误消息和200个响应代码。此外，对现有资源的一些请求可能会收到一个非200的响应。这是一个粗略的指南，告诉你在寻找隐藏内容的蛮力练习中可能遇到的响应代码的可能含义:
- 

### 1.4 Application Pages Versus Functional Paths(应用程序页面与功能路径)
### 1.5 Discovering Hidden Parameters(挖掘隐藏的参数)

# 2. Analyzing the Application(分析程序)
### 2.1 Identifying Entry Points for User Input(识别用户输入的入口点)
### 2.2 Identifying Server-Side Technologies(识别服务器端技术)
### 2.3 Identifying Server-Side Functionality(识别服务器端功能)
### 2.4 Mapping the Attack Surface(绘制攻击面)

[Web应用程序技术 - Chapter 3(2) - Web Functionality and Encoding Schemes](https://dm116.github.io/2020/03/03/web-application-technologies_2)
